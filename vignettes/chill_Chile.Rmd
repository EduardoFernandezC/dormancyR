---
title: "Compute chill metrics for Quillota, Chile"
author: "Eduardo Fernandez C <br /><small>INRES-Horticultural Sciences, University of Bonn, Auf dem Huegel 6, 53121 Bonn, Germany<small/>"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Compute chill metrics for Quillota, Chile}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography:
  - packages.bib
  - vignette.bib
csl: elsevier-harvard.csl
---
<style>
img {
display: block;
margin: 1!important;
padding: 0!important;
border: 0!important}
</style>

<img src = "dormancyR.png" alt = "dormancyR logo" align = "right" width = "20%" height = "20%"/>


<style>
body {
text-align: justify}
</style>

```{r, include = F}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, warning = F, include = F}
#Automatically write R package citation entries to a .bib file
knitr::write_bib(c(.packages(), 
                   'chillR',
                   'dplyr',
                   'ggplot2', 
                   'kableExtra',
                   'dormancyR'), 'packages.bib')
require(tidyverse)
require(kableExtra)
```

## Introduction

Winter chill directly affects tree dormancy and therefore the cultivation of deciduous fruit and nut trees [@Campoyetal2011; @Faustetal1997; @Lang1987]. To quantify chill, researchers have developed a number of mathematical models that only use temperatures as input [@Luedeling2012]. These models are normally used in orchard planing and management [@Luedeling2012]. For example, a common practice in orchard planing is to compare the historic availability of winter chill in a place with the Chill Requirement of the species and cultivar of interest to overcome winter dormancy. In this vignette, I show an example on how to use functions in the `dormancyR` [@R-dormancyR] package to handle historic weather data for Quillota, Chile. Then, I use these data to perform an analysis by using chill models in both the `dormancyR` [@R-dormancyR] and the `chillR` [@R-chillR] package.

## Step-by-step process

First, install the package from the [github repository](<https://github.com/EduardoFernandezC/dormancyR>) and load it by using the function `library`

```{r setup, eval = T}
#devtools::install_github("EduardoFernandezC/dormancyR")
library(dormancyR)
```

`dormancyR` allows to directly download historic weather data from some chilean and german databases. For [german databases](<https://cdc.dwd.de/portal/>) you can use the function `handle_cdc_germany`. For [chilean databases](http://www.cr2.cl/) you can use the function `handle_chile_cr2`. This function download historic records of temperature extremes as individual zip files (i.e. [tmin](http://www.cr2.cl/download/cr2_tasmindaily_2018_ghcn-zip/?wpdmdl=15125) and [tmax](http://www.cr2.cl/download/cr2_tasmaxdaily_2018_ghcn-zip/?wpdmdl=15126)). The function saves the files in a temporary folder. These zip files contain information for about 900 weather stations across south america since 1900 to 2017.

The first step is to define the location of interest. In this case, I will use as reference Quillota. `handle_chile_cr2` has three modes of use, retrieving 3 different outputs. At this point, it is important to use the first mode which is *info_stations*. This mode will allows to download the zip files and knowing the closest weather stations to the location of interest defined by the user in `latitude` and `longitude` parameters. The number of weather stations for which the function will give information is defined by `number_of_stations`. The period of interest is set by `begin` and `end` parameters in numeric YEARMODA format. 

```{r first_option, eval = T, warning = F}
stations <- handle_chile_cr2("info_stations", begin = 20000101, end = 20171231,
                          latitude = -32.88, longitude = -71.25, number_of_stations = 10,
                          path_zip_tmin = NULL, path_zip_tmax = NULL)
```
```{r, warning = F, echo = F, eval = T}
knitr::kable(stations[-c(1, 3)], "html", row.names = F) %>% kableExtra::kable_styling(bootstrap_options = "condensed")
```

The weather stations listed above are the 10 closest ones to the location of interest. Worth to note that the function retrieves relevant information to check the quality of the data (*N_Obs* and *Perc_days_complete* columns). In the case of the example, if a farmer owns an orchard in **Quillota** he could select and get weather data from the first station of the list.

To get the weather data in `chillR` format, `handle_chile_cr2` has to be set to the mode *my_data*. Since the zip files were already downloaded, we can use these files to extract the weather data.

```{r data, eval = T, warning = F}
path_tmin <- "temp_data/cr2_tasmindaily_2018_ghcn.zip"
path_tmax <- "temp_data/cr2_tasmaxdaily_2018_ghcn.zip"

data <- handle_chile_cr2("my_data", begin = 20000101, end = 20171231,
                          latitude = -32.88, longitude = -71.25, number_of_stations = 10,
                          path_zip_tmin = path_tmin, path_zip_tmax = path_tmax)
```
```{r, warning = F, echo = F, eval = T}
knitr::kable(head(data, 10), "html") %>% kableExtra::kable_styling(bootstrap_options = "condensed")
```

The later step returns a dataframe of weather data in the `chillR` format. However, as usual, the dataframe contains several missing data points. `perc_complete` from `dormancyR` computes the total percentage of data complete in each column of any dataframe.

```{r perc_complete, echo = F, eval = T}
perc_complete <- perc_complete(data)
knitr::kable(perc_complete(data), "html") %>% kableExtra::kable_styling(bootstrap_options = "condensed")
```

In this case, there is `r paste(round(100 - perc_complete[which(perc_complete$variable == "Tmin"), 2], 1), "%", sep = "")` and `r paste(round(100 - perc_complete[which(perc_complete$variable == "Tmax"), 2], 1), "%", sep = "")` of missing records for minimum and maximum temperatures, respectively. Most of the chill models do not allow the use of dataframes containing missing data. To fix this issue, we can use `patch_daily_temperatures` from `chillR` to fill missing days with data from close weather stations after a bias correction. To do this, the function requires a list of dataframes containing the data from alternative weather stations. This list can be provided by `handle_chile_cr2` in its last mode of use. *list_data* mode returns a list of dataframes containing weather data for all the stations listed in the *info_stations* mode, less the first weather station for which the data have been already downloaded in the *my_data* mode.

```{r list_data, eval = T}
list <- handle_chile_cr2("list_data", begin = 20000101, end = 20171231,
                          latitude = -32.88, longitude = -71.25, number_of_stations = 25,
                          path_zip_tmin = path_tmin, path_zip_tmax = path_tmax, keep_data = FALSE)
```

***Note that the `number_of_stations` parameter was set to 25 to list more dataframes***

`patch_daily_temperatures` returns a list of two elements. The first element is a dataframe containing the patched weather data. The second element is a list of length equal the number of stations used to patch the main weather dataframe. This list contains information about the mean difference and sd between both the main and alternative weather stations as well as the number of gaps that were filled. `max_mean_bias` and `max_stdev_bias` parameters set the maximum acceptable bias to use the respective weather station. If this parameter is not met, the weather station is passed on.

```{r patch_temps, eval = T}
patched <- chillR::patch_daily_temperatures(data, list, max_mean_bias = 5, max_stdev_bias = 5)
```

In this case, all the gaps were filled after using data from 13 weather stations.

Most chill models used in horticulture require hourly temperature records as input. However, some chill models used in forestry use a daily time-step. Both cases are covered by `chillR` and `dormancyR` packages. `tempResponse_daily_list` in `chillR` computes responses from several hourly models by estimating the hourly temperature through either a idealized daily temperature curve that uses a sine curve for daytime warming and a logarithmic decay function for nighttime cooling or with empirical hourly temperatures recorded at the location of interest. If the idealized curve is used, `latitude` must be provided.

```{r, eval = T}
chill_hour <- chillR::tempResponse_daily_list(patched[[1]], latitude = -32.88, Start_JDay = 121,
                                              End_JDay = 243,
                                              models = list(CH = chillR::Chilling_Hours,
                                                            UM = chillR::Utah_Model,
                                                            DM = chillR::Dynamic_Model,
                                                            MUM = modified_utah_model,
                                                            NC = north_carolina_model,
                                                            PUM = positive_utah_model,
                                                            LCM = low_chill_model), misstolerance = 5)
```
```{r, echo = F, eval = T}
knitr::kable(chill_hour[[1]][-c(2, 4)], "html") %>% kableExtra::kable_styling(bootstrap_options = "condensed")
```

The output from `tempResponse_daily_list` in `chillR` is a list containing dataframes such as the one shown above. The names of the columns for the chill models are defined in the argument `models`. Please note that **CH**, **UM** and **CP** stand for Chilling Hours [@Weinberger1950], Utah [@Richardsonetal1974] and Dynamic [@Fishmanetal1987a; @Fishmanetal1987b; @Erezetal1990] models, all of which are programmed in `chillR`. On the other hand, **MUM**, **NC**, **PUM**, and **LCM** stand for Modified Utah [@Linvill1990], North Carolina [@ShaltoutandUnrath1983], Positive Utah [@Linsley-Noakesetal1994], and Low Chill [@GilreathandBuchanan1981] models, all of which programmed in `dormancyR`. To use other chill models that use hourly temperature please see the documentation of the `dormancyR` package.

Other option is to use daily chill models such as those developed in forestry. The outputs of these models can be summarized by `tempResponse_daily` in the `dormancyR` package, an extension of `tempResponse` from `chillR`. The main difference is that `tempResponse_daily` allows the use of chill models performed with the use of daily records. This function returns a dataframe and uses as default the rate of chill (**RoC** - @Chmielewskietal2011), chill days (**CD** - @Cesaraccioetal2004), exponential chill (**ExC** - @Legaveetal2013), triangular chill Hanninen (**TrCH** - @Hanninen1990), and triangular chill Legave (**TrCL** - @Legaveetal2013) models.

```{r, eval = T}
chill_day <- tempResponse_daily(patched[[1]], Start_JDay = 121, End_JDay = 243,
                                models = list(RoC = rate_of_chill,
                                              CD = chill_days,
                                              ExC = exponential_chill,
                                              TrCH = triangular_chill_1,
                                              TrCL = triangular_chill_1))
```
```{r, echo = F, eval = T}
knitr::kable(chill_day[-c(2, 4)], "html") %>% kableExtra::kable_styling(bootstrap_options = "condensed")
```

After this analysis, and perhaps using more years of data, a farmer or farm adviser could plot the distribution of the winter chill accumulation to get an idea of the most likely values in her/his respective site. To do this, this vignette shows two examples by using the `ggplot2` package [@R-ggplot2]. One option is to plot the data by using `geom_boxplot` comparing the outputs from different chill models.

```{r boxplots, echo = F, fig.align = "center", fig.width = 6, fig.height = 4, eval = T}
chill_gather <- gather(chill_hour[[1]], "Chill Model", "Chill", colnames(chill_hour[[1]])[-c(1:5)])

ggplot(chill_gather[chill_gather$`Chill Model` == "DM", ], aes(`Chill Model`, Chill)) +
  geom_boxplot(width = 0.5, fill = "skyblue") +
  geom_boxplot(data = chill_gather[chill_gather$`Chill Model` != "DM", ], aes(`Chill Model`, Chill/15),
               width = 0.5, fill = "grey") +
  scale_y_continuous(sec.axis = sec_axis(~. * 15, name = "Chill (in rest models units - grey)")) +
  labs(y = "Chill (in Chill Portions - skyblue)") +
  theme_light()
```

Other option may be to plot the density (by using `geom_density`) of the values obtained from a given chill model.

```{r density_plot, echo = F, fig.align = "center", fig.width = 6, fig.height = 4, eval = T}
ggplot(chill_hour[[1]], aes(DM, ..density..)) +
  geom_density() +
  labs(x = "Chill Portions", y = "Density") +
  theme_light()
```

## Conclusions

`dormancyR` provides functions, such as `handle_chile_cr2`, to manage weather data and get it in an adequate format to compute relevant horticultural metrics. Most weather databases are not always performed in an user-friendly way and for most people, getting the data in an useful format is not always trivial. Moreover, after getting the data, commonly used programming interfaces do not ease the application of analysis such as those covered in this example. `dormancyR` aims to close the gap between getting the data in useful formats and computing relevant horticultural analysis such as the estimation of winter chill availability by using several modeling approaches. In this regard, `dormancyR` aims to help horticultural stakeholders in the decision-making process.

## References